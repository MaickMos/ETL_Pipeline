{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of my portfolio to demonstrate my skills in _data analytics_ and _data science_. Here I can demonstrate all the knowledge acquired in my career as a mechatronics engineer and the various courses in the work area such as Python SQL and Power BI.\n",
    "\n",
    "They are used:\n",
    "\n",
    "- SQL server 2022\n",
    "- SQL Server Management Studio (SSMS) 20.2\n",
    "- Power BI 2.138\n",
    "- Python 3.12.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries to be use\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import psycopg2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from various source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from csv file using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using library os, get the information from the files in the folder and print the folder and files names \n",
    "import os\n",
    "for dirfolder, _, filenames in os.walk('/data'):\n",
    "    for name in filenames:\n",
    "        print(os.path.join(dirfolder, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file CSV using pandas and save the data in a dataframe\n",
    "dataframe = pd.read_csv('../dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dataframe column headers\n",
    "dataframe.head()\n",
    "# The structure of the dataframe\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of null values in the data set\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # for pyhton file .py\n",
    "    PATH = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    # For Jupyter Notebook\n",
    "    PATH = Path().resolve().parent.parent\n",
    "\n",
    "with open(PATH / \"config.json\", \"r\") as f:\n",
    "    VARIABLES = json.load(f)\n",
    "\n",
    "# path of the folder with .parquet\n",
    "folder_path = Path(VARIABLES[\"file_path_sampled_box_builder_dataset\"])\n",
    "feature_frame = pd.read_csv(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Database in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    database = \"collection_tk\"\n",
    "    global connection\n",
    "    connection = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        user='postgres',\n",
    "        password = '1234',\n",
    "        database = database\n",
    "    )\n",
    "    print(\"Correct connection to database\")\n",
    "    #return True\n",
    "\n",
    "except Exception as ex:\n",
    "    print(f\" Error connecting to database: {ex}\")\n",
    "    #return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert in the column in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"tiktok_links_v1\"\n",
    "database = \"collection_tk\"\n",
    "datos = \" \"\n",
    "#for psycopg2 the table is necessary to be in lowercase, even declarad in the DB\n",
    "\n",
    "try:\n",
    "    cursor=connection.cursor()\n",
    "    encabezados = datos.columns\n",
    "    \n",
    "    #datos['ID_global'].iloc[1] #to get a specific data based in index\n",
    "    for i,_ in enumerate(datos.iterrows()):\n",
    "        row = datos.iloc[i]\n",
    "        \n",
    "        value = \"(\"\n",
    "        for j,_ in enumerate(encabezados):\n",
    "            if isinstance(row[encabezados[j]],str):\n",
    "                value += f\"'{row[encabezados[j]]}',\"\n",
    "            else:\n",
    "                value += f\"{str(row[encabezados[j]])},\"\n",
    "\n",
    "            #value = value+str(row[encabezados[j]])+\",\"\n",
    "        value = value[:-1]+\")\"\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(f\"INSERT INTO {table} VALUES {value}\")\n",
    "            print(\"executed: \"+f\"INSERT INTO {table} VALUES {value}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"error in the transaction: {ex}\")\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Upload Correctly\")\n",
    "    \n",
    "except Exception as error:\n",
    "    print(f\"Error modifying the table: {error}\")\n",
    "    connection.rollback()  # revert the transaction if there is a error\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a Querry to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querry = \"SELECT * FROM tiktok_links_v1\"\n",
    "try:\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(querry)\n",
    "    \n",
    "    #if a querry:\n",
    "    if querry.strip().upper().startswith(\"SELECT\"):\n",
    "        result= cursor.fetchall()\n",
    "        print(\"Querry successful\")\n",
    "    \n",
    "    #if diferent to a Querry\n",
    "    connection.commit()\n",
    "    print(\"Changes applied\")\n",
    "    \n",
    "\n",
    "except Exception as ex:\n",
    "    print(f\"Error al conectar a la base de datos: {ex}\")\n",
    "    connection.rollback()  # revert the transaction if there is a error\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from a Json and used to get data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "file = \"links_v1\"\n",
    "#A JSON is used to save all the path from the desktop\n",
    "#We obtain the main path of the project\n",
    "base_dir = Path().resolve()\n",
    "#path(): returns a object type path\n",
    "#.resolve: resolve posible issues eith the path\n",
    "with open(base_dir / \"config.json\", \"r\") as f:\n",
    "    paths = json.load(f)\n",
    "    #Convert a file json in a dictonary\n",
    "#Creacion de DataFrame en pandas\n",
    "datos= pd.read_csv(paths[file])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
